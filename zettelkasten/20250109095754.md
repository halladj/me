# Notes on Hadoop MapReduce:

* *HDFS* favories *throughput* over *latency*, So it is more suitable for *Batch-processing* rather than *StreamProcessing*.
* *HDFS* does not support *hard-links* or *simbolic-links*
* Typically there is one *DataNode* per real node.
* App app can specify the number of replicas of a file that should be maintained by HDFS, The number of copies(replicas) is called **replication factor**. 
* HDFS is a block-storage, each bloc is *128MB*.
* To minimize global bandwidth consumption and read latency, HDFS tries to satisfy a read request from a replica that is closest to the reader.
*  All HDFS communication protocols are layered on top of the TCP/IP protocol.  A Remote Procedure Call (RPC) abstraction wraps both the Client Protocol and the DataNode Protocol.
